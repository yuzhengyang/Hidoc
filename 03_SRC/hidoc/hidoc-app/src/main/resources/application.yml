server:
  port: 24001
  address: 0.0.0.0
  servlet:
    context-path: /
#  tomcat:
#    uri-encoding: UTF-8
#    #max-connections: 10000 #一瞬间最大支持的并发的连接数
#    accept-count: 200 #等待队列长度
#    threads:
#      max: 800
#      min-spare: 20

spring:
  application:
    name: hidoc-app

  # 数据库相关配置
  datasource:
    driverClassName: org.postgresql.Driver
    url: jdbc:postgresql://127.0.0.1:5432/hidoc
    username: postgres
    password: postgres
    type: com.alibaba.druid.pool.DruidDataSource
    # 初始化大小，最小，最大
    initialSize: 10
    minIdle: 10
    maxActive: 20
    keepAlive: true
    # 配置获取连接等待超时的时间
    maxWait: 5000
    # 高并发下会出现statement is closed等问题
    # 1.2.6版本中限制timeBetweenEvictionRunsMillis小于keepAliveBetweenTimeMillis并不能解决问题
    # 该问题出现的原因还是shrink函数中connections拷贝的bug
    minEvictableIdleTimeMillis: 180000
    setMaxEvictableIdleTimeMillis: 180000
    keepAliveBetweenTimeMillis: 120000
    timeBetweenEvictionRunsMillis: 60000
    removeAbandoned: true
    removeAbandonedTimeout: 3600
    logAbandoned: true
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    #filters: stat,slf4j
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    timeBetweenLogStatsMillis: 120000


  servlet:
    multipart:
      max-file-size: 1024MB
      max-request-size: 1024MB
  mvc:
    servlet:
      load-on-startup: 1
  cache:
    jcache:
      config: classpath:config/ehcache.xml


# mybatis-plus 输出 SQL 语句
mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #开启sql日志


#日志记录
logging:
  config: classpath:config/logging.xml
#  level:
#    com.hisense.rop.portal.mapper: debug
#    com.chz.mapper: debug
#    com.example.demo.dao: debug